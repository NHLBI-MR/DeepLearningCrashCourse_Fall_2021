{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52a8e702",
   "metadata": {},
   "source": [
    "# Deep Learning Crash Course\n",
    "## Pytorch tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351461a2-70b8-4104-9d4a-823a138f69a9",
   "metadata": {},
   "source": [
    "## Test title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99205277",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.__version__\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381f1366",
   "metadata": {},
   "source": [
    "## Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714b8fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = [3, 4, 5]\n",
    "x = torch.randn(size)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9f53d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.ones(size)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd7ccc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.zeros(size)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f033cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx = np.random.rand(2, 3)\n",
    "x = torch.from_numpy(nx)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda278bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([2, 3, 4 ,5]) \n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a7866c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[2, 3], [4, 5]]) \n",
    "print(x.shape)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60742783",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx = x.numpy()\n",
    "print(nx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba42e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[2, 3], [4, 5], [6, 7]]) \n",
    "print(x.shape)\n",
    "print(x)\n",
    "\n",
    "y = x[0:2, :]\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4fe64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[2, 3], [4, 5], [6, 7]])\n",
    "y = torch.tensor([[2, 3], [4, 5], [6, 7]])+0.2\n",
    "z = torch.cat((x, y), axis=1)\n",
    "print(z.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64cd3af2",
   "metadata": {},
   "source": [
    "Check the pytorch page : https://pytorch.org/docs/stable/tensors.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41fa4e5",
   "metadata": {},
   "source": [
    "## Autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de214367",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(1.0, requires_grad = True)\n",
    "z = x ** 3\n",
    "z.backward()\n",
    "print(x.grad.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd1bd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn((3,3), requires_grad = True)\n",
    "\n",
    "w1 = torch.randn((3,3), requires_grad = True)\n",
    "w2 = torch.randn((3,3), requires_grad = True)\n",
    "w3 = torch.randn((3,3), requires_grad = True)\n",
    "w4 = torch.randn((3,3), requires_grad = True)\n",
    "\n",
    "b = w1@a \n",
    "c = w2*a\n",
    "\n",
    "d = w3*b + w4*c \n",
    "d.retain_grad()\n",
    "\n",
    "L = torch.mean(10 - d)\n",
    "\n",
    "print(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44e32f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "L.backward()\n",
    "\n",
    "print(a.grad.data.shape)\n",
    "print(w1.grad.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2da481-8479-4c65-915c-f4f41a51cea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "d.is_leaf\n",
    "a.is_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd7fa81",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(d.requires_grad)\n",
    "print(d.grad.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705984c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "d.retain_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802435a0",
   "metadata": {},
   "source": [
    "Please read more on https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3fa1c1",
   "metadata": {},
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4391309",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90f07e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87fbc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ced761c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "img = train_features[12].squeeze()\n",
    "label = train_labels[12]\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()\n",
    "print(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4362d772",
   "metadata": {},
   "source": [
    "### write your own data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4369278",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image_array(im, label, label_names, columns=4, figsize=[32, 32]):\n",
    "    \"\"\"plot images as a panel with columns\n",
    "\n",
    "    Args:\n",
    "        im ([H, W, 3, N]): images to plot\n",
    "        columns (int, optional): number of columns in the plot. Defaults to 4.\n",
    "        figsize (list, optional): figure size. Defaults to [32, 32].\n",
    "\n",
    "    Returns:\n",
    "        fig : handle to figure\n",
    "    \"\"\"\n",
    "    fig=plt.figure(figsize=figsize)    \n",
    "\n",
    "    H, W, C, N = im.shape\n",
    "    \n",
    "    rows = np.ceil(N/columns)\n",
    "    for i in range(1, N+1):\n",
    "        fig.add_subplot(rows, columns, i)\n",
    "        if(len(im.shape)==4):\n",
    "            plt.imshow(im[:,:,:,i-1])\n",
    "        else:\n",
    "            plt.imshow(im)\n",
    "        plt.title(label_names[label[i-1]], fontsize=20)\n",
    "\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e186a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import Dataset, DataLoader, sampler\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "Project_DIR = '.'\n",
    "\n",
    "sys.path.append(Project_DIR)\n",
    "\n",
    "from util import *\n",
    "\n",
    "class Cifar10Dataset(Dataset):\n",
    "    \"\"\"Dataset for cifar-10.\"\"\"\n",
    "\n",
    "    def __init__(self, X, Y, transform=None):\n",
    "        \"\"\"Initialize the dataset\n",
    "\n",
    "        Store the X an Y into self.images and self.labels\n",
    "        Make sure self.images are in the dimension [N, C, H, W]\n",
    "\n",
    "        Args:\n",
    "            X ([32, 32, 3, N]): images\n",
    "            Y ([N]): labels\n",
    "        \"\"\"\n",
    "        # *** START CODE HERE ***\n",
    "        self.images = np.transpose(X, (3, 2, 0, 1))\n",
    "        self.labels = Y\n",
    "        assert self.images.shape[0]==self.labels.shape[0]\n",
    "        # *** END CODE HERE ***\n",
    "        \n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        \"\"\"Get the number of samples in this dataset.\n",
    "\n",
    "        Returns:\n",
    "            number of samples\n",
    "        \"\"\"\n",
    "        # *** START CODE HERE ***\n",
    "        return self.images.shape[0]\n",
    "        # *** END CODE HERE ***\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Get the idx sample\n",
    "\n",
    "        Args:\n",
    "            idx (int): the index of sample to get; first sample has idx being 0\n",
    "\n",
    "        Returns:\n",
    "            sample : a tuple (image, label)\n",
    "        \"\"\"\n",
    "        # *** START CODE HERE ***\n",
    "        N, C, H, W = self.images.shape\n",
    "        \n",
    "        if idx >= N:\n",
    "            raise \"invalid index\"\n",
    "\n",
    "        im = self.images[idx,:,:,:]\n",
    "        if self.transform:\n",
    "            # note the torchvision requires input image in [H, W, C]\n",
    "            im = self.transform(np.transpose(im, (1,2,0)))\n",
    "\n",
    "        return (im, self.labels[idx])\n",
    "        # *** END CODE HERE ***\n",
    "        \n",
    "    def __str__(self):\n",
    "        str = \"Cifar 10 Dataset\\n\"\n",
    "        str += \"  Number of images: %d\" % self.images.shape[0] + \"\\n\"\n",
    "        str += \"  Number of labels: %d\" % self.labels.shape[0] + \"\\n\"\n",
    "        str += \"  transform : %s\" % (self.transform) + \"\\n\"\n",
    "        str += \"  image shape: %d %d %d\" % self.images.shape[1:] + \"\\n\"\n",
    "            \n",
    "        return str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f069ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enable the interactive plotting\n",
    "matplotlib.use(\"tkagg\")\n",
    "\n",
    "# load dataset\n",
    "cifar10_dataset = load_and_prepare_data(os.path.join(Project_DIR, \"data\"), subtract_mean=False)\n",
    "\n",
    "with open(os.path.join(Project_DIR, \"data\", \"batches.meta\"), \"rb\") as f:\n",
    "    label_names = pickle.load(f, encoding=\"latin1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8edd67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(cifar10_dataset.keys())\n",
    "print(cifar10_dataset['X_train'].shape, cifar10_dataset['Y_train'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac50099",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the data\n",
    "f = plot_image_array(cifar10_dataset['X_train'][:,:,:,0:16], cifar10_dataset['Y_train'][0:16], label_names['label_names'], columns=4, figsize=[16, 16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f709629b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test dataset\n",
    "train_set = Cifar10Dataset(cifar10_dataset['X_train'], cifar10_dataset['Y_train'], transform=None)\n",
    "print(\"Information for training set ... \", train_set)\n",
    "test_set = Cifar10Dataset(cifar10_dataset['X_test'], cifar10_dataset['Y_test'], transform=None)\n",
    "print(\"Information for test set ... \", test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6535ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# directly get one sample\n",
    "im, label = train_set[12]\n",
    "print(\"Get one sample \", im.shape)\n",
    "\n",
    "# create and load a batch\n",
    "batch_size = 16\n",
    "num_validation = 1000\n",
    "\n",
    "dataset_size = len(train_set)\n",
    "dataset_indices = list(range(dataset_size))\n",
    "\n",
    "np.random.shuffle(dataset_indices)\n",
    "train_idx, val_idx = dataset_indices[num_validation:], dataset_indices[:num_validation]\n",
    "\n",
    "loader_for_train = DataLoader(train_set, batch_size=batch_size, sampler=sampler.SubsetRandomSampler(train_idx), pin_memory=True)\n",
    "loader_for_val = DataLoader(train_set, batch_size=batch_size, sampler=sampler.SubsetRandomSampler(val_idx), pin_memory=True)\n",
    "\n",
    "# no need to shuffle the test set\n",
    "loader_for_test = DataLoader(test_set, batch_size=batch_size, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa66f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a batch\n",
    "iter_train = iter(loader_for_train)\n",
    "images, labels = iter_train.next()\n",
    "f = plot_image_array(np.transpose(images.numpy(), (2,3,1,0)), labels.numpy(), label_names['label_names'], columns=4, figsize=[32, 32])\n",
    "\n",
    "iter_val = iter(loader_for_val)\n",
    "images, labels = iter_val.next()\n",
    "f = plot_image_array(np.transpose(images.numpy(), (2,3,1,0)), labels.numpy(), label_names['label_names'], columns=4, figsize=[32, 32])\n",
    "\n",
    "iter_test = iter(loader_for_test)\n",
    "images, labels = iter_test.next()\n",
    "f = plot_image_array(np.transpose(images.numpy(), (2,3,1,0)), labels.numpy(), label_names['label_names'], columns=4, figsize=[32, 32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0ad15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now, add some random transformation\n",
    "transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomVerticalFlip(p=0.5),\n",
    "        transforms.RandomRotation(degrees=90.0)\n",
    "])\n",
    "\n",
    "# set the transform\n",
    "train_set.transform = transform\n",
    "\n",
    "# now plot a batch\n",
    "images, labels = iter_train.next()\n",
    "f = plot_image_array(np.transpose(images.numpy(), (2,3,1,0)), labels.numpy(), label_names['label_names'], columns=4, figsize=[32, 32])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d05169",
   "metadata": {},
   "source": [
    "## Train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a0b3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_test_accuracy(loader, model, loss_func, device=torch.device('cpu')):\n",
    "    \n",
    "    running_loss_train = 0.0\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(loader, 0):\n",
    "            x, y = data            \n",
    "            x = x.to(device=device, dtype=torch.float32)\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "                                          \n",
    "            y_hat = model(x)\n",
    "            loss = loss_func(y_hat, y)\n",
    "            \n",
    "            _, predicted = torch.max(y_hat.data, 1)\n",
    "            total += y.size(0)\n",
    "            correct += (predicted == y).sum().item()\n",
    "            \n",
    "            running_loss_train += loss.item()\n",
    "\n",
    "        loss = running_loss_train / (i+1)\n",
    "        accu = correct / total\n",
    "    \n",
    "    return loss, accu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfc9f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 30\n",
    "num_hidden_layers = [300, 200, 200, 200, 100]\n",
    "batch_size = 4096\n",
    "reg = 1e-4\n",
    "learning_rate = 0.1\n",
    "use_gpu = True\n",
    "one_batch_training = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e408849",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class PytorchMLP(nn.Module):\n",
    "\n",
    "    def __init__(self, H, W, C, num_hidden_layers):\n",
    "        \"\"\"Initial the model\n",
    "\n",
    "        Please create the pytorch layers for MLP. Please use ReLU as the nonlinear activation. \n",
    "        Hints: torch.nn.Sequential may be useful. Also, check torch.nn.Linear and torch.nn.ReLU\n",
    "\n",
    "        Args:\n",
    "            H (int): Height of input image\n",
    "            W (int): Width of input image\n",
    "            C (int): Number of channels of input image\n",
    "            num_hidden_layers (list, optional): number of hidden layers. Defaults to [300, 300, 200, 100].\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        self.blocks = nn.Sequential()\n",
    "        for i, num_neurons in enumerate(num_hidden_layers):\n",
    "            if(i==0):\n",
    "                input_dim = int(H*W*C)\n",
    "            else:\n",
    "                input_dim = num_hidden_layers[i-1]\n",
    "                \n",
    "            output_dim = num_neurons\n",
    "                \n",
    "            self.blocks.add_module(\"fc_%d\" % i, nn.Linear(input_dim, output_dim, bias=True))\n",
    "            self.blocks.add_module(\"relu_%d\" % i, nn.ReLU())\n",
    "                \n",
    "        self.blocks.add_module(\"fc_output\", nn.Linear(output_dim, 10, bias=True))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass of MLP model\n",
    "\n",
    "        Args:\n",
    "            x ([B, C, H, W]): a batch of input image\n",
    "\n",
    "        Returns:\n",
    "            output ([B, 10]): logits tensor, ready for the softmax\n",
    "        \"\"\"\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.blocks(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ecddc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(cifar10_dataset, num_samples_validation=1000):\n",
    "    \"\"\"Run the training\n",
    "\n",
    "    Inputs:\n",
    "        cifar10_dataset : dataset loaded with utlity functions\n",
    "        num_samples_validation : number of samples for validation\n",
    "\n",
    "    Outputs:\n",
    "        model : model after training\n",
    "        loss_train, loss_val : loss for every epoch\n",
    "        accu_train, accu_val : accuracy for every epoch\n",
    "    \"\"\"\n",
    "\n",
    "    # add some data transformation\n",
    "    transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "            transforms.RandomVerticalFlip(p=0.5)\n",
    "    ])\n",
    "\n",
    "    # set up the data loader\n",
    "    train_set = Cifar10Dataset(cifar10_dataset['X_train'], cifar10_dataset['Y_train'], transform=transform)\n",
    "    # do not add data augmentation to test set !\n",
    "    test_set = Cifar10Dataset(cifar10_dataset['X_test'], cifar10_dataset['Y_test'], transform=None)\n",
    "    \n",
    "    # create and load a batch    \n",
    "    dataset_size = len(train_set)\n",
    "    dataset_indices = list(range(dataset_size))\n",
    "    np.random.shuffle(dataset_indices)\n",
    "\n",
    "    if(one_batch_training):\n",
    "        print(\"Train with only one batch\")\n",
    "        train_idx, val_idx = dataset_indices[num_samples_validation:num_samples_validation+batch_size], dataset_indices[:num_samples_validation]\n",
    "    else:\n",
    "        train_idx, val_idx = dataset_indices[num_samples_validation:], dataset_indices[:num_samples_validation]\n",
    "\n",
    "    loader_for_train = DataLoader(train_set, batch_size=batch_size, sampler=sampler.SubsetRandomSampler(train_idx), pin_memory=True)\n",
    "    loader_for_val = DataLoader(train_set, batch_size=batch_size, sampler=sampler.SubsetRandomSampler(val_idx), pin_memory=True)\n",
    "\n",
    "    H, W, C, B = cifar10_dataset['X_train'].shape\n",
    "    \n",
    "    # declare the model\n",
    "    m = PytorchMLP(H, W, C, num_hidden_layers)\n",
    "    print(m)        \n",
    "    \n",
    "    # declare the loss function\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # declare the optimizer\n",
    "    optimizer = optim.SGD(m.parameters(), lr=learning_rate, momentum=0.9, weight_decay=reg)\n",
    "    \n",
    "    # check the device\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda')\n",
    "        \n",
    "    if (use_gpu is False):\n",
    "        device = torch.device('cpu')\n",
    "    \n",
    "    # set model to device\n",
    "    m.to(device=device)\n",
    "\n",
    "    loss_train = []\n",
    "    loss_val = []\n",
    "    accu_train = []\n",
    "    accu_val = []\n",
    "\n",
    "    # train for num_epochs\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        m.train()\n",
    "        \n",
    "        # go through all mini-batches for this epoch\n",
    "        running_loss_train = 0.0\n",
    "        running_accu_train = 0.0\n",
    "        for i, data in enumerate(loader_for_train, 0):\n",
    "\n",
    "            x, y = data\n",
    "            x = x.to(device=device, dtype=torch.float32) \n",
    "            y = y.to(device=device, dtype=torch.long) \n",
    "                          \n",
    "            # forward pass, put the model output to y_hat\n",
    "            y_hat = m(x)\n",
    "\n",
    "            # compute loss\n",
    "            loss = loss_func(y_hat, y)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "            # backprop\n",
    "            loss.backward()\n",
    "            \n",
    "            # perform gradient descent step\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss_train += loss.item()            \n",
    "            running_accu_train += compute_accuracy(y_hat.detach().cpu(), y.detach().cpu())\n",
    "            \n",
    "        # after one epoch, compute training loss and accuracy\n",
    "        loss_train.append(running_loss_train/(i+1))\n",
    "        accu_train.append(running_accu_train/(i+1))\n",
    "\n",
    "        # after one epoch, compute validation loss and accuracy\n",
    "        lv, av = compute_test_accuracy(loader_for_val, m, loss_func, device=device)\n",
    "        loss_val.append(lv)\n",
    "        accu_val.append(av)\n",
    "\n",
    "        print('epoch %d, train loss %f, accuracy %f - val loss %f, accuracy %f' % (epoch, loss_train[epoch], accu_train[epoch], loss_val[epoch], accu_val[epoch]))\n",
    "\n",
    "    # compute test accuracy\n",
    "    test_set = Cifar10Dataset(cifar10_dataset['X_test'], cifar10_dataset['Y_test'], transform=None)\n",
    "    loader_for_test = DataLoader(test_set, batch_size=batch_size, pin_memory=True)\n",
    "    loss_test, accu_test = compute_test_accuracy(loader_for_test, m, loss_func, device=device)\n",
    "    \n",
    "    return m, loss_train, loss_val, loss_test, accu_train, accu_val, accu_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544d73da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_samples_validation = 3000\n",
    "best_model, loss_train, loss_val, loss_test, accu_train, accu_val, accu_test = run_training(cifar10_dataset, num_samples_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1a893f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2, 1)\n",
    "\n",
    "ax1.plot(np.arange(num_epochs), loss_train,'r', label='train')\n",
    "ax1.plot(np.arange(num_epochs), loss_val, 'b', label='validation')\n",
    "ax1.set_xlabel('epochs')\n",
    "ax1.set_ylabel('loss')\n",
    "ax1.legend()\n",
    "\n",
    "ax2.plot(np.arange(num_epochs), accu_train,'r', label='train')\n",
    "ax2.plot(np.arange(num_epochs), accu_val, 'b', label='validation')\n",
    "ax2.set_xlabel('epochs')\n",
    "ax2.set_ylabel('accuracy')\n",
    "ax2.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e300d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
